# Train-a-Word2Vec-Model-From-Scratch
This project demonstrates how to train a Word2Vec model from scratch using gensim on a custom text corpus and use it to generate meaningful word embeddings for downstream tasks like sentiment analysis, clustering, or semantic similarity.
ðŸš€ Features
Trains a Word2Vec model using gensim.models.Word2Vec

Supports both CBOW and Skip-Gram

Preprocessing using gensim.utils.simple_preprocess

Extracts word embeddings and averages them to generate sentence vectors

Ready for integration with classification models (e.g., Logistic Regression, Random Forest)

